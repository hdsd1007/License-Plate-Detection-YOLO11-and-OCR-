{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import easyocr                                  # We will use Deeplearning based OCR => EasyOCR\n",
    "import re                                       # Regex = Regular Expression\n",
    "from collections import defaultdict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda9f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our fine tuned model\n",
    "model = YOLO(\"license_plate_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OCR reader [Will be language specific]\n",
    "reader = easyocr.Reader(['en'],gpu=True)            # Specified English Language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the image before its feed to the OCR\n",
    "def plate_preprocess(plate_image):\n",
    "    if plate_image.size == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    # Pre-process for OCR for converting it to Grey Scale\n",
    "    grey_image = cv2.cvtColor(plate_image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(grey_image, (3, 3), 0)\n",
    "    \n",
    "    # Adaptive thresholding works better than fixed threshold\n",
    "    thres = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Non-adaptive Thresholding\n",
    "    #_,thres = cv2.threshold(grey_image, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # We resize to put more emphasis on the plate. Resizing adds new pixels so we use interpolation to smoothen the image out\n",
    "    plate_resized = cv2.resize(thres,None,fx=3,fy=3,interpolation=cv2.INTER_CUBIC) \n",
    "    \n",
    "    try:\n",
    "        ocr_result = reader.readtext(\n",
    "            plate_resized,\n",
    "            detail=0,                                               # Will only give the text recognized for each item in the list\n",
    "            paragraph=True,                                         # Will combine them into one\n",
    "            allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890',       # Since Majority of License Plate are Capitalized\n",
    "            \n",
    "        )\n",
    "        if ocr_result:\n",
    "            cleaned_text = ocr_result[0].strip().upper().replace(\" \",\"\")\n",
    "            return cleaned_text \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1dc9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a buffer to get stable image for the OCR \n",
    "plate_history = defaultdict(lambda: deque(maxlen=12))   # Smaller buffer for faster response\n",
    "plate_final = {}\n",
    "plate_confidence = defaultdict(int)                     # Track confidence of final result\n",
    "\n",
    "def get_stable_pattern(track_id, new_text):\n",
    "    if new_text and len(new_text.replace(\" \", \"\")) >= 3:  # Accept any text with 3+ characters\n",
    "        # Clean the text but don't enforce format\n",
    "        cleaned_text = new_text.strip().upper()\n",
    "        \n",
    "        if cleaned_text:  # If we have valid text\n",
    "            plate_history[track_id].append(cleaned_text)\n",
    "            \n",
    "            # Count occurrences\n",
    "            text_counts = {}\n",
    "            for text in plate_history[track_id]:\n",
    "                text_counts[text] = text_counts.get(text, 0) + 1\n",
    "            \n",
    "            # Get most common text and its count\n",
    "            most_common = max(text_counts, key=text_counts.get)\n",
    "            max_count = text_counts[most_common]\n",
    "            \n",
    "            # Only update final result if we have reasonable confidence\n",
    "            if max_count >= 2:  # Require at least 2 occurrences (more responsive)\n",
    "                if track_id not in plate_final or max_count > plate_confidence[track_id]:\n",
    "                    plate_final[track_id] = most_common\n",
    "                    plate_confidence[track_id] = max_count\n",
    "    \n",
    "    return plate_final.get(track_id, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_overlay(frame, x1, y1, x2, y2, text, track_id):\n",
    "    # Get stable text\n",
    "    stable_text = get_stable_pattern(track_id, text)\n",
    "    \n",
    "    # Show overlay if we have a stable reading with confidence >= 2\n",
    "    if stable_text and plate_confidence[track_id] >= 2:\n",
    "        overlay_h, overlay_w = 150, 400\n",
    "        \n",
    "        # Calculate overlay position above the plate\n",
    "        oy1 = max(0, y1 - overlay_h - 40)\n",
    "        ox1 = x1\n",
    "        oy2, ox2 = oy1 + overlay_h, ox1 + overlay_w\n",
    "        \n",
    "        # Ensure overlay fits within frame bounds\n",
    "        if ox2 > frame.shape[1]:\n",
    "            ox1 = frame.shape[1] - overlay_w\n",
    "            ox2 = frame.shape[1]\n",
    "        \n",
    "        # Check for valid cropping coordinates\n",
    "        if y2 > y1 and x2 > x1:\n",
    "            plate_crop = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            # Resize and paste the zoomed-in plate\n",
    "            if plate_crop is not None and plate_crop.size > 0:\n",
    "                plate_resized = cv2.resize(plate_crop, (overlay_w, overlay_h))\n",
    "                if oy1 >= 0 and oy2 <= frame.shape[0] and ox1 >= 0 and ox2 <= frame.shape[1]:\n",
    "                    frame[oy1:oy2, ox1:ox2] = plate_resized\n",
    "\n",
    "        # Show the stable text\n",
    "        display_text = f\"{stable_text}\"\n",
    "        \n",
    "        # Draw text with outline for better visibility\n",
    "        cv2.putText(frame, display_text, (ox1, oy1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 5)\n",
    "        cv2.putText(frame, display_text, (ox1, oy1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the input and output for the Video, along with Video Codex\n",
    "input_video = \"input_video.mp4\"\n",
    "output_video = \"output_video.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video,\n",
    "                      fourcc,\n",
    "                      cap.get(cv2.CAP_PROP_FPS),\n",
    "                      (int(cap.get(3)),        # WIDTH of the FRAME from the CAPTURE\n",
    "                      int(cap.get(4)))         # HEIGHT of the FRAME from the CAPTURE\n",
    "                      )\n",
    "\n",
    "CONF_THRES = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Stream Ended or File not able to read..\n"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Video Stream Ended or File not able to read..\")\n",
    "        break\n",
    "    \n",
    "    results = model.track(frame,persist=True,verbose=False)    # We pass the frame to the model\n",
    "    \n",
    "    for r in results:\n",
    "        \n",
    "        boxes = r.boxes\n",
    "        \n",
    "        if boxes.id is not None:\n",
    "            track_ids = boxes.id.int().tolist() # We convert id's to int and keep them in a list\n",
    "            \n",
    "            # Using Vectorized approach for faster calculation\n",
    "            high_conf_indices = [i for i, conf in enumerate(boxes.conf) if float(conf) > CONF_THRES]\n",
    "            \n",
    "            # interate through the indices that pass our CONF_THRES\n",
    "            for i in high_conf_indices:\n",
    "                box = boxes[i]\n",
    "                track_id = track_ids[i]\n",
    "\n",
    "                x1,y1,x2,y2 = box.xyxy.int().tolist()[0]\n",
    "                \n",
    "                # Crop the plate for the current box\n",
    "                plate_crop = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                # OCR with correction, processing a single image\n",
    "                text = plate_preprocess(plate_crop)\n",
    "                                \n",
    "                # Draw rectangle around the number plate\n",
    "                cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),3)\n",
    "\n",
    "                # Get the stable text (Number) and overlay it on top the box\n",
    "                zoom_overlay(frame, x1, y1, x2, y2, text, track_id)\n",
    "                        \n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dfec45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
